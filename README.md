# -Transformer-based-Reward-Shaping-RL
This is a transformer-based reward shaping, which utilizes unlabelled trajectories to train the transformer module as a potential function for state-based and goal-based reward reinforcement environments. This repository is an ongoing work for AAAI2024 submission. The simulation environment includes four continuous state based learning tasks: Hopper, Humanoid, HalfCheetah, Walker2D; and four discrete goal based reward learning tasks: Minigrid FourRooms, Minigrid MultiRooms, Minigrid EmptyRooms. We compared it with three benchmarks: TD3, a model-free DRL algorithm; BMPO, a model-based algorithm; and BiPaRS, an adaptive reward shaping algorithm, to compare with our TBRS method.
